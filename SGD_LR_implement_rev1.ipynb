{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7eiDWcM_MC3H"
   },
   "source": [
    "# <font color='red'>Implement SGD Classifier with Logloss and L2 regularization Using SGD without using sklearn</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yfe2NTQtLq11"
   },
   "source": [
    "**There will be some functions that start with the word \"grader\" ex: grader_weights(), grader_sigmoid(), grader_logloss() etc, you should not change those function definition.<br><br>Every Grader function has to return True.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Fk5DSPCLxqT-"
   },
   "source": [
    "<font color='red'> Importing packages</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "42Et8BKIxnsp"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NpSk3WQBx7TQ"
   },
   "source": [
    "<font color='red'>Creating custom dataset</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BsMp0oWzx6dv"
   },
   "outputs": [],
   "source": [
    "# please don't change random_state\n",
    "X, y = make_classification(n_samples=50000, n_features=15, n_informative=10, n_redundant=5,\n",
    "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)\n",
    "# make_classification is used to create custom dataset \n",
    "# Please check this link (https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html) for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "L8W2fg1cyGdX",
    "outputId": "029d4c84-03b2-4143-a04c-34ff49c88890"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((50000, 15), (50000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x99RWCgpqNHw"
   },
   "source": [
    "<font color='red'>Splitting data into train and test </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0Kh4dBfVyJMP"
   },
   "outputs": [],
   "source": [
    "#please don't change random state\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0DR_YMBsyOci",
    "outputId": "732014d9-1731-4d3f-918f-a9f5255ee149"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37500, 15), (37500,), (12500, 15), (12500,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BW4OHswfqjHR"
   },
   "source": [
    "# <font color='red' size=5>SGD classifier</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "3HpvTwDHyQQy",
    "outputId": "5729f08c-079a-4b17-bf51-f9aeb5abb13b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
       "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
       "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "              penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
       "              tol=0.001, validation_fraction=0.1, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# alpha : float\n",
    "# Constant that multiplies the regularization term. \n",
    "\n",
    "# eta0 : double\n",
    "# The initial learning rate for the ‘constant’, ‘invscaling’ or ‘adaptive’ schedules.\n",
    "\n",
    "clf = linear_model.SGDClassifier(eta0=0.0001, alpha=0.0001, loss='log', random_state=15, penalty='l2', tol=1e-3, verbose=2, learning_rate='constant')\n",
    "clf\n",
    "# Please check this documentation (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 638
    },
    "colab_type": "code",
    "id": "YYaVyQ2lyXcr",
    "outputId": "dc0bf840-b37e-4552-e513-84b64f6c64c4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.77, NNZs: 15, Bias: -0.316653, T: 37500, Avg. loss: 0.455552\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.91, NNZs: 15, Bias: -0.472747, T: 75000, Avg. loss: 0.394686\n",
      "Total training time: 0.01 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.98, NNZs: 15, Bias: -0.580082, T: 112500, Avg. loss: 0.385711\n",
      "Total training time: 0.03 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 1.02, NNZs: 15, Bias: -0.658292, T: 150000, Avg. loss: 0.382083\n",
      "Total training time: 0.05 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 1.04, NNZs: 15, Bias: -0.719528, T: 187500, Avg. loss: 0.380486\n",
      "Total training time: 0.07 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 1.05, NNZs: 15, Bias: -0.763409, T: 225000, Avg. loss: 0.379578\n",
      "Total training time: 0.09 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 1.06, NNZs: 15, Bias: -0.795106, T: 262500, Avg. loss: 0.379150\n",
      "Total training time: 0.11 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 1.06, NNZs: 15, Bias: -0.819925, T: 300000, Avg. loss: 0.378856\n",
      "Total training time: 0.13 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 1.07, NNZs: 15, Bias: -0.837805, T: 337500, Avg. loss: 0.378585\n",
      "Total training time: 0.14 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 1.08, NNZs: 15, Bias: -0.853138, T: 375000, Avg. loss: 0.378630\n",
      "Total training time: 0.16 seconds.\n",
      "Convergence after 10 epochs took 0.16 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0001,\n",
       "              fit_intercept=True, l1_ratio=0.15, learning_rate='constant',\n",
       "              loss='log', max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "              penalty='l2', power_t=0.5, random_state=15, shuffle=True,\n",
       "              tol=0.001, validation_fraction=0.1, verbose=2, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X=X_train, y=y_train) # fitting our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 101
    },
    "colab_type": "code",
    "id": "EAfkVI6GyaRO",
    "outputId": "bc88f920-6531-4106-9b4c-4dabb6d72b47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.42336692,  0.18547565, -0.14859036,  0.34144407, -0.2081867 ,\n",
       "          0.56016579, -0.45242483, -0.09408813,  0.2092732 ,  0.18084126,\n",
       "          0.19705191,  0.00421916, -0.0796037 ,  0.33852802,  0.02266721]]),\n",
       " (1, 15),\n",
       " array([-0.8531383]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_, clf.coef_.shape, clf.intercept_\n",
    "#clf.coef_ will return the weights\n",
    "#clf.coef_.shape will return the shape of weights\n",
    "#clf.intercept_ will return the intercept term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_-CcGTKgsMrY"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "# This is formatted as code\n",
    "```\n",
    "\n",
    "## <font color='red' size=5> Implement Logistic Regression with L2 regularization Using SGD: without using sklearn </font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W1_8bdzitDlM"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "1.  We will be giving you some functions, please write code in that functions only.\n",
    "\n",
    "2.  After every function, we will be giving you expected output, please make sure that you get that output. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zU2Y3-FQuJ3z"
   },
   "source": [
    "\n",
    "<br>\n",
    "\n",
    "* Initialize the weight_vector and intercept term to zeros (Write your code in <font color='blue'>def initialize_weights()</font>)\n",
    "\n",
    "* Create a loss function (Write your code in <font color='blue'>def logloss()</font>) \n",
    "\n",
    " $log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$\n",
    "- for each epoch:\n",
    "\n",
    "    - for each batch of data points in train: (keep batch size=1)\n",
    "\n",
    "        - calculate the gradient of loss function w.r.t each weight in weight vector (write your code in <font color='blue'>def gradient_dw()</font>)\n",
    "\n",
    "        $dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)})$ <br>\n",
    "\n",
    "        - Calculate the gradient of the intercept (write your code in <font color='blue'> def gradient_db()</font>) <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>check this</a>\n",
    "\n",
    "           $ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t}))$\n",
    "\n",
    "        - Update weights and intercept (check the equation number 32 in the above mentioned <a href='https://drive.google.com/file/d/1nQ08-XY4zvOLzRX-lGf8EYB5arb7-m1H/view?usp=sharing'>pdf</a>): <br>\n",
    "        $w^{(t+1)}← w^{(t)}+α(dw^{(t)}) $<br>\n",
    "\n",
    "        $b^{(t+1)}←b^{(t)}+α(db^{(t)}) $\n",
    "    - calculate the log loss for train and test with the updated weights (you can check the python assignment 10th question)\n",
    "    - And if you wish, you can compare the previous loss and the current loss, if it is not updating, then\n",
    "        you can stop the training\n",
    "    - append this loss in the list ( this will be used to see how loss is changing for each epoch after the training is over )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZR_HgjgS_wKu"
   },
   "source": [
    "<font color='blue'>Initialize weights </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GecwYV9fsKZ9"
   },
   "outputs": [],
   "source": [
    "def initialize_weights(dim):\n",
    "    ''' In this function, we will initialize our weights and bias'''\n",
    "    dim = X_train[0] \n",
    "    w = np.zeros_like(dim)\n",
    "    w = w.reshape(1,-1)\n",
    "    b = 0\n",
    "    #initialize the weights to zeros array of (1,dim) dimensions\n",
    "    #you use zeros_like function to initialize zero, check this link https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros_like.html\n",
    "    #initialize bias to zero\n",
    "\n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A7I6uWBRsKc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w = [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "b = 0\n",
      "Wall time: 1.28 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dim=X_train[0] \n",
    "w,b = initialize_weights(dim)\n",
    "print('w =',(w))\n",
    "print('b =',str(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4MI5SAjP9ofN"
   },
   "source": [
    "<font color='cyan'>Grader function - 1 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pv1llH429wG5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dim=X_train[0] \n",
    "w,b = initialize_weights(dim)\n",
    "def grader_weights(w,b):\n",
    "    assert((len(w[0])==len(dim)) and b==0 and np.sum(w)==0.0)\n",
    "    return True\n",
    "grader_weights(w,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QN83oMWy_5rv"
   },
   "source": [
    "<font color='blue'>Compute sigmoid </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qPv4NJuxABgs"
   },
   "source": [
    "$sigmoid(z)= 1/(1+exp(-z))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nAfmQF47_Sd6"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def sigmoid(z):\n",
    "    ''' In this function, we will return sigmoid of z'''\n",
    "    # compute sigmoid(z) and return\n",
    "\n",
    "    return 1. / (1 + np. exp(-z))\n",
    "\n",
    "# https://stackoverflow.com/questions/3985619/how-to-calculate-a-logistic-sigmoid-function-in-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9YrGDwg3Ae4m"
   },
   "source": [
    "<font color='cyan'>Grader function - 2</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "P_JASp_NAfK_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_sigmoid(z):\n",
    "    val=sigmoid(z)\n",
    "    assert(val==0.8807970779778823)\n",
    "    return True\n",
    "grader_sigmoid(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gS7JXbcrBOFF"
   },
   "source": [
    "<font color='blue'> Compute loss </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lfEiS22zBVYy"
   },
   "source": [
    "$log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VaFDgsp3sKi6"
   },
   "outputs": [],
   "source": [
    "from math import log\n",
    "def logloss(y_true,y_pred):\n",
    "    \n",
    "    '''In this function, we will compute log loss '''\n",
    "\n",
    "    loss = -sum(map(lambda y_true, y_pred: y_true*np.log10(y_pred) + (1-y_true)*np.log10(1-y_pred), y_true, y_pred))/len(y_true)\n",
    "\n",
    "    return loss\n",
    "\n",
    "# # https://www.kaggle.com/c/march-machine-learning-mania-2015/discussion/12444"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Zs1BTXVSClBt"
   },
   "source": [
    "<font color='cyan'>Grader function - 3 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LzttjvBFCuQ5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_logloss(true,pred):\n",
    "    loss=logloss(true,pred)\n",
    "    assert(loss==0.07644900402910389)\n",
    "    return True\n",
    "true=[1,1,0,1,0]\n",
    "pred=[0.9,0.8,0.1,0.8,0.2]\n",
    "grader_logloss(true,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07644900402910389"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true=[1,1,0,1,0]\n",
    "pred=[0.9,0.8,0.1,0.8,0.2]\n",
    "logloss(true,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tQabIadLCBAB"
   },
   "source": [
    "<font color='blue'>Compute gradient w.r.to  'w' </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YTMxiYKaCQgd"
   },
   "source": [
    "$dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)}$ <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NMVikyuFsKo5"
   },
   "outputs": [],
   "source": [
    "def gradient_dw(x,y,w,b,alpha,N):\n",
    "    '''In this function, we will compute the gardient w.r.to w '''\n",
    "\n",
    "    dw = x * (y - sigmoid(np.dot(w, x) + b)) - (alpha / N) * w\n",
    "\n",
    "\n",
    "    return dw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RUFLNqL_GER9"
   },
   "source": [
    "<font color='cyan'>Grader function - 4 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WI3xD8ctGEnJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_dw(x,y,w,b,alpha,N):\n",
    "    grad_dw=gradient_dw(x,y,w,b,alpha,N)\n",
    "    assert(np.sum(grad_dw)==2.613689585)\n",
    "    return True\n",
    "grad_x=np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
    "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
    "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
    "grad_y=0\n",
    "grad_w,grad_b=initialize_weights(grad_x)\n",
    "alpha=0.0001\n",
    "N=len(X_train)\n",
    "grader_dw(grad_x,grad_y,grad_w,grad_b,alpha,N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LE8g84_GI62n"
   },
   "source": [
    "<font color='blue'>Compute gradient w.r.to 'b' </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fHvTYZzZJJ_N"
   },
   "source": [
    "$ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0nUf2ft4EZp8"
   },
   "outputs": [],
   "source": [
    " def gradient_db(x,y,w,b):\n",
    "        '''In this function, we will compute gradient w.r.to b '''\n",
    "        db = y - sigmoid(np.dot(w, x) + b)\n",
    "\n",
    "        return db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pbcBzufVG6qk"
   },
   "source": [
    "<font color='cyan'>Grader function - 5 </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TfFDKmscG5qZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def grader_db(x,y,w,b):\n",
    "    grad_db=gradient_db(x,y,w,b)\n",
    "    assert(grad_db==-0.5)\n",
    "    return True\n",
    "grad_x=np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
    "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
    "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
    "grad_y=0\n",
    "grad_w,grad_b=initialize_weights(grad_x)\n",
    "alpha=0.0001\n",
    "N=len(X_train)\n",
    "grader_db(grad_x,grad_y,grad_w,grad_b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TCK0jY_EOvyU"
   },
   "source": [
    "<font color='blue'> Implementing logistic regression</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8.56 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tqdm import tqdm\n",
    "\n",
    "loss_tr=[]\n",
    "loss_ts=[]\n",
    "epoch_list = []\n",
    "def train(X_train,y_train,X_test,y_test,epochs,alpha,eta0):\n",
    "    ''' In this function, we will implement logistic regression'''\n",
    "\n",
    "    w,b = initialize_weights(X_train[0])\n",
    "    eta0 = 0.0001\n",
    "    \n",
    "    for e in tqdm(range(epochs)):\n",
    "        y_tr_pred=[]\n",
    "        y_ts_pred=[]\n",
    "        for i in range(len(X_train)):\n",
    "            \n",
    "            w = w + (eta0 * gradient_dw(X_train[i], y_train[i], w, b, alpha, N))\n",
    "            b = b + (eta0 * gradient_db(X_train[i], y_train[i], w, b))\n",
    "\n",
    "        for k in range(len(X_train)):\n",
    "            z = np.dot(w,X_train[k])+b\n",
    "            s = sigmoid(z)\n",
    "            y_tr_pred.append(s)\n",
    "        l_tr = logloss(y_train,y_tr_pred)\n",
    "        loss_tr.append(l_tr)\n",
    "\n",
    "        for j in range(len(X_test)):\n",
    "            z_test = np.dot(w,X_test[j])+b\n",
    "            s_test = sigmoid(z_test)\n",
    "            y_ts_pred.append(s_test) \n",
    "        l_ts = logloss(y_test,y_ts_pred)\n",
    "        loss_ts.append(l_ts)\n",
    "\n",
    "        epoch_list.append(e)\n",
    "        \n",
    "    return w,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sUquz7LFEZ6E"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 50/50 [03:11<00:00,  3.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 11s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "alpha=0.0001\n",
    "eta0=0.0001\n",
    "N=len(X_train)\n",
    "epochs=50\n",
    "w,b=train(X_train,y_train,X_test,y_test,epochs,alpha,eta0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-4.29755932e-01,  1.93023807e-01, -1.48464457e-01,\n",
       "          3.38103415e-01, -2.21228940e-01,  5.69932597e-01,\n",
       "         -4.45183638e-01, -8.99209785e-02,  2.21804834e-01,\n",
       "          1.73809448e-01,  1.98727704e-01, -5.59450918e-04,\n",
       "         -8.13106259e-02,  3.39094296e-01,  2.29784893e-02]]),\n",
       " array([-0.8918926]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w,b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l4Zf_wPARlwY"
   },
   "source": [
    "<font color='red'>Goal of assignment</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l3eF_VSPSH2z"
   },
   "source": [
    "Compare your implementation and SGDClassifier's the weights and intercept, make sure they are as close as possible i.e difference should be in terms of 10^-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nx8Rs9rfEZ1R"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-0.00638902,  0.00754815,  0.0001259 , -0.00334065, -0.01304224,\n",
       "          0.00976681,  0.00724119,  0.00416715,  0.01253163, -0.00703181,\n",
       "          0.0016758 , -0.00477861, -0.00170693,  0.00056628,  0.00031128]]),\n",
       " array([-0.0387543]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these are the results we got after we implemented sgd and found the optimal weights and intercept\n",
    "w-clf.coef_, b-clf.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "230YbSgNSUrQ"
   },
   "source": [
    "<font color='blue'>Plot epoch number vs train , test loss </font>\n",
    "\n",
    "* epoch number on X-axis\n",
    "* loss on Y-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1O6GrRt7UeCJ"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.figure()\n",
    "plt.plot((epoch_list), (loss_tr), label = \"Train\")\n",
    "plt.plot((epoch_list), (loss_ts), label = \"Test\")\n",
    "plt.title(\"Train vs Test Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FUN8puFoEZtU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.95224\n",
      "0.95\n"
     ]
    }
   ],
   "source": [
    "def pred(w,b, X):\n",
    "    N = len(X)\n",
    "    predict = []\n",
    "    for i in range(N):\n",
    "        z=np.dot(w,X[i])+b\n",
    "        if sigmoid(z) >= 0.5: # sigmoid(w,x,b) returns 1/(1+exp(-(dot(x,w)+b)))\n",
    "            predict.append(1)\n",
    "        else:\n",
    "            predict.append(0)\n",
    "    return np.array(predict)\n",
    "print(1-np.sum(y_train - pred(w,b,X_train))/len(X_train))\n",
    "print(1-np.sum(y_test  - pred(w,b,X_test))/len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
